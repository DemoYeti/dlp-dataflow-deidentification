name: "Cleanup resources"
description: "Cleanup BQ and Dataflow job"
inputs:
  job_id:
    description: "JobId"
    required: false
  project_id:
    description: "project_id"
    required: true
  dataset:
    description: "dataset"
    required: true
  input_gcs_bucket:
    description: "Bucket with run time created files"
    required: true
  job_type:
    description: "Batch/Streaming"
    required: true

runs:
  using: "composite"
  steps:
    - name: Cleanup BQ Tables
      shell: bash
      run: bq rm -r -f -d ${{inputs.project_id}}:${{inputs.dataset}}

#    - name: Cleanup GCS files
#      if: always() && inputs.job_type  == 'streaming'
#      shell: bash
#      run: gcloud storage rm gs://${{inputs.input_gcs_bucket}}/*
