name: "Cleanup resources"
description: "Cleanup BQ and Dataflow job"
inputs:
  job_id:
    description: "JobId"
    required: false
  project_id:
    description: "project_id"
    required: true
  dataset:
    description: "dataset"
    required: true
  input_gcs_bucket_path:
    description: "Bucket with run time created files"
    required: true
  job_type:
    description: "Batch/Streaming"
    required: true

runs:
  using: "composite"
  steps:
    - name: Cleanup BQ Tables
      shell: bash
      run: bq rm -r -f -d ${{inputs.project_id}}:${{inputs.dataset}}

    - name: Cleanup GCS files
      if: always() && inputs.job_type == 'streaming'
      shell: bash
      run: gcloud storage rm ${{inputs.input_gcs_bucket_path}}

    - name: Delete pub/sub notification config
      if: always() && inputs.job_type == 'streaming'
      shell: bash
      run: gsutil notification delete ${{inputs.input_gcs_bucket_path}}
